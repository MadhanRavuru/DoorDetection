{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python3.6","language":"python","name":"python3.6"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"PyTorch_Object_Detection.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wHSZ_i20p2jU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600541055842,"user_tz":-120,"elapsed":51700,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}},"outputId":"2683452d-e3a5-45a0-ee2f-932a2669bbe5"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/Siemens Work/DoorDetection'    #project folder directory"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i7x3L-_Xp3Vb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600541057820,"user_tz":-120,"elapsed":714,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}},"outputId":"f9ae0831-c6ed-4dfb-8f02-0e3c70ef307d"},"source":["%cd 'gdrive/My Drive/Siemens Work/DoorDetection'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Siemens Work/DoorDetection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f7GMtTBZp0EG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600541065994,"user_tz":-120,"elapsed":6152,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}}},"source":["from models import *\n","from utils import *\n","\n","import os, sys, time, datetime, random\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image\n","from numpy import asarray"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"XeVWrzl1p0EP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1600541079535,"user_tz":-120,"elapsed":17188,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}},"outputId":"a083faa4-7062-4e72-e561-398cbdf9d8e8"},"source":["config_path='config/yolov3.cfg'\n","weights_path='config/yolov3.weights'\n","class_path='config/coco.names'\n","img_size=416\n","conf_thres=0.9\n","nms_thres=0.1\n","\n","# Load model and weights\n","model = Darknet(config_path, img_size=img_size)\n","model.load_weights(weights_path)\n","model.cuda()\n","model.eval()\n","classes = utils.load_classes(class_path)\n","Tensor = torch.cuda.FloatTensor"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"i1Agi65Vp0EX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600541087152,"user_tz":-120,"elapsed":508,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}}},"source":["def detect_image(img):\n","    # scale and pad image\n","    ratio = min(img_size/img.size[0], img_size/img.size[1])\n","    imw = round(img.size[0] * ratio)\n","    imh = round(img.size[1] * ratio)\n","    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n","         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n","                        (128,128,128)),\n","         transforms.ToTensor(),\n","         ])\n","    # convert image to Tensor\n","    image_tensor = img_transforms(img).float()\n","    image_tensor = image_tensor.unsqueeze_(0)\n","    input_img = Variable(image_tensor.type(Tensor))\n","    # run inference on the model and get detections\n","    with torch.no_grad():\n","        detections = model(input_img)\n","        detections = utils.non_max_suppression(detections, 1, conf_thres, nms_thres)\n","    return detections[0]"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u4o1O9P0JMOT","colab_type":"text"},"source":["**Splitting image into 9 equal parts(3x3)**"]},{"cell_type":"code","metadata":{"id":"NejXp6jE9-LY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600541171665,"user_tz":-120,"elapsed":3793,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}}},"source":["img = Image.open('images/split/test.jpg')\n","im = asarray(img)\n","\n","M = im.shape[0]//3\n","N = im.shape[1]//3                 \n","image_paths = []\n","count = 0\n","for x in range(0,im.shape[0],M):\n","  for y in range(0,im.shape[1],N):\n","     if ((im.shape[0]-x < 2) | (im.shape[1]-y < 2)):  #leaving out images, which are long and skinny\n","        continue\n","     else:\n","        count = count + 1\n","        tile = im[x:x+M,y:y+N]\n","        Image.fromarray(tile).save('images/split/' + str(count) + '.jpg')\n","\n","        image_paths.append('images/split/' + str(count) + '.jpg')"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MsqlMGvyJaKX","colab_type":"text"},"source":["**Load image and get detections for splitted images**"]},{"cell_type":"code","metadata":{"id":"cUhzjVWDp0Ed","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1eG7pkVOvm7QpuQCEPttpTsCHeBkPub7b"},"executionInfo":{"status":"ok","timestamp":1600541198102,"user_tz":-120,"elapsed":9154,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}},"outputId":"46edbba6-e166-42b5-818f-dc4ca1d4bb2e"},"source":["for file_ in image_paths:\n","  img_path = file_\n","  prev_time = time.time()\n","  img = Image.open(img_path)\n","  img = img.convert('RGB')\n","  detections = detect_image(img)\n","  inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n","  print ('Inference Time: %s' % (inference_time))\n","  if detections is None:\n","   print('No detections')\n","# Get bounding-box colors\n","#cmap = plt.get_cmap('tab20b')\n","#colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n","\n","\n","  img = np.array(img)\n","  plt.figure()\n","  fig, ax = plt.subplots(1, figsize=(12,9))\n","  ax.imshow(img)\n","\n","  pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n","  pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n","  unpad_h = img_size - pad_y\n","  unpad_w = img_size - pad_x\n","  \n","  if detections is not None:\n","    unique_labels = detections[:, -1].cpu().unique()\n","    n_cls_preds = len(unique_labels)\n","    #bbox_colors = random.sample(colors, n_cls_preds)\n","    # browse detections and draw bounding boxes\n","    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n","        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n","        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n","        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n","        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n","        img_path = file_\n","  prev_time = time.time()\n","  img = Image.open(img_path)\n","  img = img.convert('RGB')\n","  detections = detect_image(img)\n","  inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n","  print ('Inference Time: %s' % (inference_time))\n","  if detections is None:\n","   print('No detections')\n","# Get bounding-box colors\n","#cmap = plt.get_cmap('tab20b')\n","#colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n","\n","\n","  img = np.array(img)\n","  plt.figure()\n","  fig, ax = plt.subplots(1, figsize=(12,9))\n","  ax.imshow(img)\n","\n","  pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n","  pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n","  unpad_h = img_size - pad_y\n","  unpad_w = img_size - pad_x\n","  \n","  if detections is not None:\n","    unique_labels = detections[:, -1].cpu().unique()\n","    n_cls_preds = len(unique_labels)\n","    #bbox_colors = random.sample(colors, n_cls_preds)\n","    # browse detections and draw bounding boxes\n","    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n","        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n","        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n","        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n","        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n","        \n","        #color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n","        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=3, edgecolor='green', facecolor='none')\n","        ax.add_patch(bbox)\n","      \n","        #plt.text(x1, y1, s=classes[int(cls_pred)], color='white', verticalalignment='top',\n","        #        bbox={'color': 'green', 'pad': 0})\n","  plt.axis('off')\n","# save image\n","  plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"), bbox_inches='tight', pad_inches=0.0)\n","  plt.show()"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"NKQCnMSjJkRC","colab_type":"text"},"source":["**Merge the smaller detected images to get full detected image**"]},{"cell_type":"code","metadata":{"id":"7t19XrCC4D9v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600541244549,"user_tz":-120,"elapsed":1096,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}}},"source":["import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","\n","range_x = im.shape[0]//M\n","range_y = im.shape[1]//N\n","\n","count = 0\n","detected_img = Image.open(image_paths[count].replace(\".jpg\", \"-det.jpg\"))\n","w = detected_img.size[0]\n","h = detected_img.size[1]\n","f_w = w*range_x\n","f_h = h*range_y\n","final_detected_img = Image.new('RGB', (f_w,f_h))\n","\n","for x in range(range_x):\n","  for y in range(range_y):\n","        detected_img = Image.open(image_paths[count].replace(\".jpg\", \"-det.jpg\"))\n","        final_detected_img.paste(detected_img, (w*y,h*x))\n","        count = count + 1"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQv559r8p0Ek","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600541249436,"user_tz":-120,"elapsed":671,"user":{"displayName":"Madhan R","photoUrl":"","userId":"14169875594351604346"}}},"source":["final_detected_img.save(\"images/split/final_detected_img.jpg\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"4l8lKME_NaFz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}